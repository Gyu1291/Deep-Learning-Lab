{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upEJK8UUDnyn"
   },
   "source": [
    "> ### EEE4423: Deep Learning Lab\n",
    "\n",
    "# LAB \\#12: Sequence to Sequence Network with Attention Module\n",
    "## Machine Translation with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAv1aaG8Dnys"
   },
   "source": [
    "<h4><div style=\"text-align: right\"> Due date: May 27, 2022. </div> <br>\n",
    "<div style=\"text-align: right\"> Please upload your file @ LearnUs by 9 AM in the form of [ID_Name_Lab12.ipynb]. </div></h4>\n",
    "\n",
    "### *Instructions:*\n",
    "- Write a program implementing a particular algorithm to solve a given problem.   \n",
    "- <span style=\"color:red\">**Report and discuss your results. Analyze the algorithm, theoretically and empirically.**</span> \n",
    "- Each team must write their own answers and codes (<span style=\"color:red\">**if not you will get a F grade**</span>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SULIl9bRDnys"
   },
   "source": [
    "<h2><span style=\"color:blue\">[Insert your ID HERE] [Insert your name HERE]</span> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2JP0LD9nDnys",
    "outputId": "0c1a8aae-4843-435b-dbaa-9624d918ff03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is written at 2023-05-22 13:06:15.238998\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"This code is written at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBvC_gonDnyu"
   },
   "source": [
    "In this project we will be teaching a neural network to translate from\n",
    "French to English.\n",
    "*************************************************************\n",
    "::\n",
    "\n",
    "    [(>): input, (=): target, (<): output]\n",
    "\n",
    "    > il est en train de peindre un tableau .\n",
    "    = he is painting a picture .\n",
    "    < he is painting a picture .\n",
    "\n",
    "    > pourquoi ne pas essayer ce vin delicieux ?\n",
    "    = why not try that delicious wine ?\n",
    "    < why not try that delicious wine ?\n",
    "\n",
    "    > elle n est pas poete mais romanciere .\n",
    "    = she is not a poet but a novelist .\n",
    "    < she not not a poet but a novelist .\n",
    "\n",
    "    > vous etes trop maigre .\n",
    "    = you re too skinny .\n",
    "    < you re all alone .\n",
    "\n",
    "...\n",
    "*************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nLSIcUoZDnyu"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v0s8XW7Dnyv"
   },
   "source": [
    "### 1. Prepare data\n",
    "\n",
    "The data for this project is a set of many thousands of English to French translation pairs. Download the data from <https://download.pytorch.org/tutorial/data.zip>. The file is a tab separated list of translation pairs:\n",
    "\n",
    "\n",
    "    I am cold.    J'ai froid.\n",
    "    \n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1K3W2RxeTKih5IiT5PcIyWNZSwMqtYSGZ\"  onerror=\"this.style.display='none'\" style=\"width: 600px;\"/><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Xn2soUCGDnyv",
    "outputId": "a76ed812-6017-4ceb-a52c-2fd70a6b1377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counted words: fra = 4345 eng = 2803\n",
      "['je ne vais pas m en meler .', 'i m not going to get involved .']\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \")\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    # Read the file and split into lines\n",
    "    lines = open('./dataset-dllab/lab12/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\", input_lang.name, '=', input_lang.n_words, output_lang.name, '=', output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "A8yVC59WDnyw"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4qXkB3DDnyw"
   },
   "source": [
    "### 2. Build the Seq2Seq model [5 points]\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1kKXrIIxi0t-Nm5HfzOukqjzEp7yEXEpV\"  onerror=\"this.style.display='none'\" /><br><br>\n",
    "\n",
    "[sequence to sequence network](https://arxiv.org/abs/1409.3215) is a model in which two\n",
    "recurrent neural networks work together to transform one sequence to\n",
    "another. An encoder network condenses an input sequence into a single vector,\n",
    "and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input\n",
    "corresponds to an output, the seq2seq model frees us from sequence\n",
    "length and order, which makes it ideal for translation between two\n",
    "languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDTwMr5TDnyy"
   },
   "source": [
    "#### Encoder\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.  \n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1PyKBEVl5jwQfB0I0P2kG8nTGQVZQdZEM\"  onerror=\"this.style.display='none'\" /><br><br>\n",
    "\n",
    "#### GRU\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1467jVFRYbw1DYvVKeSyzGWLRmtlqpy8z\"  onerror=\"this.style.display='none'\" style=\"width: 700px;\"/><br><br>\n",
    "The GRU operates using a reset gate (r) and an update gate (z). The candidate state is created by using the previous hidden state and the current input. It is the reset gate that determines how the previous hidden state affects the candidate state. The newly created candidate state and the previous hidden state create a new hidden state, in which the update gate plays a role in balancing the two.\n",
    "\n",
    "#### LSTM vs GRU\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1lzGTsIYvPWKNF-XaTevMaaZvjfgp9G35\"  onerror=\"this.style.display='none'\" style=\"width: 600px;\"/><br><br>\n",
    "\n",
    "| <center>LSTM</center> | <center>GRU</center>  |\n",
    "|:--------|--------|\n",
    "| LSTM has 3 gates (forget, input, output) | GRU has 2 gates (reset, update) |\n",
    "| There is an internal memory (cell state) | There is no cell state and only hidden state exists |\n",
    "| When making output, another non-linearity is applied | There is no additional non-linearity when making output  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PpL3bajyDnyy"
   },
   "outputs": [],
   "source": [
    "# 2 points\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "\n",
    "        # GRU\n",
    "        # The size of input is (batch_size, seq_dim, hidden_dim)\n",
    "        self.z_gate_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.z_gate_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.r_gate_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.r_gate_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.hh_gate_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.hh_gate_hr = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x, hn):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        input_x = x.view(1,1,-1)\n",
    "        \n",
    "        #Size match is needed\n",
    "        \n",
    "        #input_x = x[:, t, :]\n",
    "        z_t = self.sigmoid(self.z_gate_x(input_x) + self.z_gate_h(hn))\n",
    "        r_t = self.sigmoid(self.r_gate_x(input_x) + self.r_gate_h(hn))\n",
    "        h_hat_t = self.tanh(self.hh_gate_x(input_x) + self.hh_gate_hr(hn*r_t))\n",
    "        hn = (1-z_t)*h_hat_t + z_t*hn\n",
    "        output = hn\n",
    "        \n",
    "        #output = output.reshape(length, self.input_dim)\n",
    "        \n",
    "        return output, hn\n",
    "\n",
    "    def initHidden(self):\n",
    "        # The size of h0 should be (1, 1, hidden_dim)\n",
    "        h0 = torch.zeros(1, 1, self.hidden_dim).cuda()\n",
    "        return h0\n",
    "    \n",
    "hidden_dim = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGjPPHD7Dnyy"
   },
   "source": [
    "#### Decoder\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1Rm_LlpEolCvPuzPWEFOZ-zdTfsgMbtu-\"  onerror=\"this.style.display='none'\" /><br><br>\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder, that single vector carries the burden of encoding the entire sentence. Attention allows the decoder network to \"focus\" on a specific part of\n",
    "the encoder's outputs for every step and thus help the decoder choose the right output words. \n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=18hsS8PAA7I3QaN9oOebfnMGAMhR-6EID\"  onerror=\"this.style.display='none'\" style=\"width: 170px;\"/><br><br>\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1F1Y92uLvGaI6s-ygyNKNox4ZGiZmTZ3g\"  onerror=\"this.style.display='none'\" style=\"width: 170px;\"/><br><br>\n",
    "\n",
    "The attention weights are calculated using an another feed-forward layer which inputs the decoder's input and hidden state. And the calculated attention weight is multiplied to the corresponding hidden state of the encoder, respectively. Note that to actually create and train this layer we have to choose a maximum sentence length. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1JEE23gtJf4XciJUXLt2R9lZtpRn8mYCN\"  onerror=\"this.style.display='none'\" /><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "NfWr22rFDnyz"
   },
   "outputs": [],
   "source": [
    "# 3 points\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_dim, self.hidden_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        # attention\n",
    "        # Note that the column of the attention weights is MAX_LENGTH\n",
    "        # Note that concatenation is used when \"attn\" and \"attn_combine\" are created\n",
    "        self.attn = nn.Linear(self.hidden_dim*2, MAX_LENGTH)\n",
    "        self.attn_combine = nn.Linear(self.hidden_dim*2, self.hidden_dim)\n",
    "        \n",
    "        # gru\n",
    "        # The size of input is (batch_size, seq_dim, hidden_dim)\n",
    "        self.z_gate_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.z_gate_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.r_gate_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.r_gate_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.hh_gate_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.hh_gate_hr = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.out = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, input, hn, encoder_outputs):\n",
    "        input = self.embedding(input).view(1, 1, -1)\n",
    "        input = self.dropout(input)\n",
    "        \n",
    "        # attention\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((input[0], hn[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        concat = torch.cat((input[0], attn_applied[0]), 1)\n",
    "        attn_combine = self.attn_combine(concat).unsqueeze(0)\n",
    "        r_attn_combine = F.relu(attn_combine) #after ReLU\n",
    "        \n",
    "        # gru\n",
    "        input_x = r_attn_combine.view(1,1,-1)\n",
    "        \n",
    "        #Size match is needed\n",
    "        #input_x = r_attn_combine[:, t, :]\n",
    "        z_t = self.sigmoid(self.z_gate_x(input_x) + self.z_gate_h(hn))\n",
    "        r_t = self.sigmoid(self.r_gate_x(input_x) + self.r_gate_h(hn))\n",
    "        h_hat_t = self.tanh(self.hh_gate_x(input_x) + self.hh_gate_hr(hn*r_t))\n",
    "        hn = (1-z_t)*h_hat_t + z_t*hn\n",
    "            #output = torch.cat([output, hn])\n",
    "        \n",
    "        output = hn\n",
    "        #output = output.reshape(length, self.input_dim)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        return output, hn\n",
    "\n",
    "    def initHidden(self):\n",
    "        # The size of h0 should be (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = torch.zeros(1,1, self.hidden_size)\n",
    "        return h0\n",
    "    \n",
    "decoder = AttnDecoderRNN(hidden_dim, output_lang.n_words, dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg2utJ-1Dnyz"
   },
   "source": [
    "### 3. Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "KE-npWCODnyz"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate=0.01\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMr9RcDBDnyz"
   },
   "source": [
    "### 4. Write the evaluation code [2 points]\n",
    "\n",
    "- Using the trained model, display the translated output given input sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "UO3UzfFCDnyz"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        #############\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_dim, device=device)\n",
    "        #############\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "        \n",
    "        \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoded_words = []\n",
    "        \n",
    "        #############\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for di in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        #############\n",
    "\n",
    "        return decoded_words\n",
    "    \n",
    "def evaluateRandomly():\n",
    "    pair = random.choice(pairs)\n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7wNENhXDnyz"
   },
   "source": [
    "### 5 . Write the code to train the model [3 points]\n",
    "\n",
    "- During training, use the `Teacher forcing` concept in addition to a naive approach.\n",
    "    - In other words, instead of using the decoder's guess as the next input, the real target outputs are also used sometimes. This shows faster convergence.\n",
    "- Plot the training loss curve.\n",
    "- Show the result using $evaluateRandomly()$ function. Below is an example.\n",
    "*************************************************************\n",
    "    > il est en train de peindre un tableau . (input)\n",
    "    = he is painting a picture . (target)\n",
    "    < he is painting a picture . (output)\n",
    "*************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "9x83bK3GDnyz",
    "outputId": "34533830-f22b-4080-bc51-582d4993b8e2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* iter1000 *************************\n",
      "loss 22.9581\n",
      "> je vais me marier .\n",
      "= i m going to get married .\n",
      "< i m really to . <EOS>\n",
      "\n",
      "************************* iter2000 *************************\n",
      "loss 8.9215\n",
      "> vous arrivez trop tard .\n",
      "= you are too late .\n",
      "< you re going to . . . <EOS>\n",
      "\n",
      "************************* iter3000 *************************\n",
      "loss 14.7418\n",
      "> je suis satisfaite de leur representation .\n",
      "= i m pleased with their performance .\n",
      "< i m sorry of my . . <EOS>\n",
      "\n",
      "************************* iter4000 *************************\n",
      "loss 15.7179\n",
      "> vous etes creatif .\n",
      "= you re creative .\n",
      "< you re rude . <EOS>\n",
      "\n",
      "************************* iter5000 *************************\n",
      "loss 28.4550\n",
      "> je suis completement vanne .\n",
      "= i m completely exhausted .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "************************* iter6000 *************************\n",
      "loss 6.1060\n",
      "> je me rejouis vraiment que tu sois la .\n",
      "= i m really glad you re here .\n",
      "< i m glad that that that here . <EOS>\n",
      "\n",
      "************************* iter7000 *************************\n",
      "loss 19.2888\n",
      "> il fume plus que jamais .\n",
      "= he s smoking more than ever .\n",
      "< he s than he s a . <EOS>\n",
      "\n",
      "************************* iter8000 *************************\n",
      "loss 11.6140\n",
      "> nous sommes sur le chemin de la maison .\n",
      "= we are on the way home .\n",
      "< we re in the the the . . <EOS>\n",
      "\n",
      "************************* iter9000 *************************\n",
      "loss 12.1135\n",
      "> je suis vannee .\n",
      "= i m exhausted .\n",
      "< i m being . <EOS>\n",
      "\n",
      "************************* iter10000 *************************\n",
      "loss 21.3502\n",
      "> j en suis certain .\n",
      "= i m certain of that .\n",
      "< i m sorry . <EOS>\n",
      "\n",
      "************************* iter11000 *************************\n",
      "loss 16.5806\n",
      "> c est une jeune femme tres intelligente .\n",
      "= she is a very intelligent young lady .\n",
      "< she is a very tall very busy . <EOS>\n",
      "\n",
      "************************* iter12000 *************************\n",
      "loss 24.2467\n",
      "> tu es tres gentil .\n",
      "= you re very nice .\n",
      "< you re very sophisticated . <EOS>\n",
      "\n",
      "************************* iter13000 *************************\n",
      "loss 9.6207\n",
      "> il est jeune et celibataire .\n",
      "= he s young and single .\n",
      "< he s a and old . <EOS>\n",
      "\n",
      "************************* iter14000 *************************\n",
      "loss 15.6270\n",
      "> tu es occupe en ce moment ?\n",
      "= you are busy now aren t you ?\n",
      "< you re in now aren t <EOS>\n",
      "\n",
      "************************* iter15000 *************************\n",
      "loss 12.4694\n",
      "> on est foutu .\n",
      "= we re sunk .\n",
      "< i m getting . <EOS>\n",
      "\n",
      "************************* iter16000 *************************\n",
      "loss 15.1283\n",
      "> vous etes fascinants .\n",
      "= you re fascinating .\n",
      "< you re courteous . <EOS>\n",
      "\n",
      "************************* iter17000 *************************\n",
      "loss 5.8509\n",
      "> je n ai pas fini .\n",
      "= i m not done .\n",
      "< i m not done . <EOS>\n",
      "\n",
      "************************* iter18000 *************************\n",
      "loss 7.0407\n",
      "> je suis desolee de t avoir derangee !\n",
      "= i m sorry to have bothered you .\n",
      "< i m sorry to have bothered you . <EOS>\n",
      "\n",
      "************************* iter19000 *************************\n",
      "loss 14.6713\n",
      "> on me traite comme un enfant .\n",
      "= i m being treated like a child .\n",
      "< i m just a a a . <EOS>\n",
      "\n",
      "************************* iter20000 *************************\n",
      "loss 1.7672\n",
      "> nous sommes tres excites a ce propos .\n",
      "= we re very excited about that .\n",
      "< we re all ready for this this . <EOS>\n",
      "\n",
      "************************* iter21000 *************************\n",
      "loss 9.3201\n",
      "> pour moi c est la fin des haricots .\n",
      "= i m at the end of my rope .\n",
      "< i m right in the . . <EOS>\n",
      "\n",
      "************************* iter22000 *************************\n",
      "loss 27.4772\n",
      "> ils s en vont .\n",
      "= they re leaving .\n",
      "< they re going to have the <EOS>\n",
      "\n",
      "************************* iter23000 *************************\n",
      "loss 12.3346\n",
      "> je suis contente que vous soyez la .\n",
      "= i m glad you could be here .\n",
      "< i m glad you re here . <EOS>\n",
      "\n",
      "************************* iter24000 *************************\n",
      "loss 5.5915\n",
      "> je suis reellement fiere de toi .\n",
      "= i m really proud of you .\n",
      "< i m proud of you . <EOS>\n",
      "\n",
      "************************* iter25000 *************************\n",
      "loss 3.8212\n",
      "> je gagne .\n",
      "= i m winning .\n",
      "< i m getting . <EOS>\n",
      "\n",
      "************************* iter26000 *************************\n",
      "loss 1.0062\n",
      "> je suis membre de ce club de tennis .\n",
      "= i m in the tennis club .\n",
      "< i m a with the new . <EOS>\n",
      "\n",
      "************************* iter27000 *************************\n",
      "loss 5.3963\n",
      "> j ai la dalle .\n",
      "= i m starved .\n",
      "< i m very hungry . <EOS>\n",
      "\n",
      "************************* iter28000 *************************\n",
      "loss 4.1192\n",
      "> je suis loin de chez moi .\n",
      "= i m a long way from home .\n",
      "< i m home home at home . <EOS>\n",
      "\n",
      "************************* iter29000 *************************\n",
      "loss 12.0801\n",
      "> elle est accoutumee a veiller toute la nuit .\n",
      "= she is used to staying up all night .\n",
      "< she is used to all . <EOS>\n",
      "\n",
      "************************* iter30000 *************************\n",
      "loss 3.2857\n",
      "> je suis en chemin pour mon travail .\n",
      "= i m on my way to work .\n",
      "< i m on my my my job . <EOS>\n",
      "\n",
      "************************* iter31000 *************************\n",
      "loss 20.6168\n",
      "> je suis trop occupe pour l aider .\n",
      "= i m too busy to help him .\n",
      "< i m too busy to help him . <EOS>\n",
      "\n",
      "************************* iter32000 *************************\n",
      "loss 14.5724\n",
      "> je vais dechiffrer ca .\n",
      "= i m going to figure this out .\n",
      "< i m going to this this . <EOS>\n",
      "\n",
      "************************* iter33000 *************************\n",
      "loss 5.8093\n",
      "> maintenant je suis tres heureuse .\n",
      "= i m very happy now .\n",
      "< i m very happy happy . <EOS>\n",
      "\n",
      "************************* iter34000 *************************\n",
      "loss 5.8851\n",
      "> j etudie a la bibliotheque .\n",
      "= i m studying in the library .\n",
      "< i m studying in the . . <EOS>\n",
      "\n",
      "************************* iter35000 *************************\n",
      "loss 12.8857\n",
      "> tu entends des choses .\n",
      "= you are hearing things .\n",
      "< you are hearing things . <EOS>\n",
      "\n",
      "************************* iter36000 *************************\n",
      "loss 4.8291\n",
      "> ce sont des eleves .\n",
      "= they re students .\n",
      "< they are students . <EOS>\n",
      "\n",
      "************************* iter37000 *************************\n",
      "loss 14.6955\n",
      "> il est egoiste et cupide .\n",
      "= he is selfish and greedy .\n",
      "< he is cruel and clever . <EOS>\n",
      "\n",
      "************************* iter38000 *************************\n",
      "loss 1.2325\n",
      "> nous prenons le controle .\n",
      "= we re taking over .\n",
      "< we re feeling . . . <EOS>\n",
      "\n",
      "************************* iter39000 *************************\n",
      "loss 18.0272\n",
      "> je fais mon devoir .\n",
      "= i m doing my duty .\n",
      "< i m doing my my . . <EOS>\n",
      "\n",
      "************************* iter40000 *************************\n",
      "loss 30.5814\n",
      "> vous etes une de ces menteuses !\n",
      "= you are such a liar !\n",
      "< you re such a liar ! <EOS>\n",
      "\n",
      "************************* iter41000 *************************\n",
      "loss 1.9531\n",
      "> il est riche .\n",
      "= he s rich .\n",
      "< he s rich . <EOS>\n",
      "\n",
      "************************* iter42000 *************************\n",
      "loss 3.9108\n",
      "> ils sont libres .\n",
      "= they re free .\n",
      "< they re free . <EOS>\n",
      "\n",
      "************************* iter43000 *************************\n",
      "loss 7.5763\n",
      "> nous ne sommes plus vraiment amies .\n",
      "= we re not really friends anymore .\n",
      "< we re not really good . <EOS>\n",
      "\n",
      "************************* iter44000 *************************\n",
      "loss 0.2594\n",
      "> elle est gentille .\n",
      "= she s nice .\n",
      "< she is kind . <EOS>\n",
      "\n",
      "************************* iter45000 *************************\n",
      "loss 0.4305\n",
      "> il a peur des chiens .\n",
      "= he is afraid of dogs .\n",
      "< he s afraid of dogs . <EOS>\n",
      "\n",
      "************************* iter46000 *************************\n",
      "loss 27.7426\n",
      "> il est fou .\n",
      "= he s demented .\n",
      "< he s a . . <EOS>\n",
      "\n",
      "************************* iter47000 *************************\n",
      "loss 10.9516\n",
      "> il aime beaucoup la musique .\n",
      "= he is very fond of music .\n",
      "< he is fond fond of music . <EOS>\n",
      "\n",
      "************************* iter48000 *************************\n",
      "loss 0.8914\n",
      "> ceci m est indifferent .\n",
      "= i am not concerned with this .\n",
      "< i am still with to . . <EOS>\n",
      "\n",
      "************************* iter49000 *************************\n",
      "loss 24.5135\n",
      "> je ne suis pas un menteur .\n",
      "= i m no liar .\n",
      "< i m not a liar . <EOS>\n",
      "\n",
      "************************* iter50000 *************************\n",
      "loss 0.3605\n",
      "> vous etes productif .\n",
      "= you re productive .\n",
      "< you re productive . <EOS>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f05dd353ba8>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_iters = 50000\n",
    "print_every = 1000\n",
    "plot_every =100\n",
    "\n",
    "plot_losses = []\n",
    "print_loss_total = 0  # Reset every print_every\n",
    "plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "\n",
    "for iter in range(1, n_iters+1):\n",
    "    # Load data\n",
    "    training_pair = training_pairs[iter-1]\n",
    "    input_tensor = training_pair[0]\n",
    "    target_tensor = training_pair[1]\n",
    "    \n",
    "    # Clear gradients w.r.t. parameters\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    #print(input_lang.n_words)\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = 0\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    #############\n",
    "    # CODE HERE #\n",
    "    #############\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_dim, device=device)\n",
    "    #print(input_tensor)\n",
    "    #print(input_tensor[0].size())\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    \n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    teacher_forcing_ratio = 0.5\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            #decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Updating parameters\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    print_loss_total += loss.item() / target_length\n",
    "    plot_loss_total += loss.item() / target_length\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('*'*25, 'iter%d'%iter, '*'*25)\n",
    "        print('loss %.4f'%loss)\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        evaluateRandomly()\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "\n",
    "#################################################\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrccVZ1gDny0"
   },
   "source": [
    "### *References*\n",
    "[1] [practical pytorch](https://github.com/spro/practical-pytorch)(https://github.com/spro/practical-pytorch)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EEE4423_lab11_Seq2Seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Full on Python 3.6 (GPU)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
